{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b31e33c1-0d88-4906-8ddf-ae685d5d14e3",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd83f198-598b-49e9-8064-f5a998d79d67",
   "metadata": {},
   "source": [
    "This note taking is a short summary about one of the Machine Learning course series by Dr. Andrew Ng provided at Coursera. (https://www.coursera.org/learn/machine-learning/lecture/PNeuX/what-is-machine-learning) There might be my thoughts inlcuded in the script below. Please feel free to contact me with any quesitons or corrections to be made. The series of the courses consists of three parts:\n",
    "1) Supervised Machine Learning: Regression and Classification\n",
    "  - Week1: Supervised/Unsupervised, Cost function, Gradient descent\n",
    "  - Week2: Regression with multiple input variables\n",
    "  - Week3: Classification with logistic regression, Sigmoid function\n",
    "2) Advanced Learning Algorithms\n",
    "  - Week1: Neural networks\n",
    "  - Week2: Neural network training\n",
    "  - Week3: Decision trees\n",
    "3) Unsupervised Machine Learning: Recommenders, Reinforcement learning\n",
    "  - Week1: K-means clustering, Anomaly detection\n",
    "  - Week2: Recommender system, PCA\n",
    "  - Week3: Reinforcement learning, State-action value function, Bellman equation, Algorithm refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8117c39a-ecd5-4ed2-a054-36f1b1660ba6",
   "metadata": {},
   "source": [
    "### What is Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20d0c58-4d73-4bb2-816a-c708ac93c9fc",
   "metadata": {},
   "source": [
    "Field of study that gives computers the ability to learn without being explicitly programmed. (by Arthur Samuel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85124fd1-617e-4b62-9d0a-da1150e9a948",
   "metadata": {},
   "source": [
    "#### Supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088872f4-9478-4554-92c4-11431db9b66d",
   "metadata": {},
   "source": [
    "I would conclude that the key of Supervised learning is 'with knowing the answer y, train the machine with algorithms and predict future y only with given x', in other words, train the machine 'with' answers and make the machine smarter for 'prediction'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a2b17a-bf85-46ea-88a8-7e304a52a80b",
   "metadata": {},
   "source": [
    "Transcript: You give learning algorithm examples to learn from that includes the right answers, correct label y for a given input x, and is by seeing correct pairs of input x and desired output label y that the learning algorithm eventually learns to take just the input alone without the output label and gives a reasonably accurate \"prediction\" or \"guess\" of the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fa7bce-039a-4b50-8536-1502c6ca4665",
   "metadata": {},
   "source": [
    "- Example: spam or not, text translation, click ad or not, position of other cars\n",
    "- Inputs can be email, audio, texts, image and etc.\n",
    "- Classification is one of the supervised learning problems. (There are many other types like regression.)\n",
    "- Classification predict categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a574f73-23fc-4b63-83b2-a0131125778e",
   "metadata": {},
   "source": [
    "#### Unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85830ca4-99ec-45fd-9b02-6cc1ff756524",
   "metadata": {},
   "source": [
    "Without right answers, the machine learns data by itself. Data only comes with inputs x, but not output labels y. Algorithm has to find structure in the data. Therefore PCA, and other methods for dimensionality reduction can be categorized in 'unsupervised learning'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46df515-f18f-486a-a16c-d572ccde939a",
   "metadata": {},
   "source": [
    "- Example: clustering, segmentation, anomaly detection, dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ee92f8-5d3f-4696-aa52-ae39b5bd192e",
   "metadata": {},
   "source": [
    "### Cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df1d73a-9693-42bc-88ec-8be77b0b96f7",
   "metadata": {},
   "source": [
    "#### Sqaured error cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e405479-bc9a-4ea5-8203-336fa83632ec",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{error:} (\\hat{y}^{(i)} - y^{(i)})^2 \\\\\n",
    "\\text{sum of error:} \\sum_{i=1}^{m}(\\hat{y}^{(i)} - y^{(i)})^2\\\\\n",
    "J(w,b) = \\frac{1}{2m}\\sum_{i=1}^{m}(\\hat{y}^{(i)} - y^{(i)})^2\\\\\n",
    "\\text{while, } m = \\text{number of training examples}\\\\\n",
    "\\text{goal: } \\text{minimize}_{w, b} J(w,b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0391929a-0c0d-4a21-a8c1-8d3b623ee17c",
   "metadata": {},
   "source": [
    "The goal of linear regression is to find the parameters w or w and b that results in the smallest possible value for the cost function J. Since J is the cost, difference between the prediction and the real true vale, we need to find the parameters to minimize this difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3ef81b-69ae-427d-a14f-7d5a65cf0d0a",
   "metadata": {},
   "source": [
    "When referring to the plots expressing cost functions, we can check that the cost function is the function of w (parameters) and its minimum point is the point where the model's accuracy is smallest, where the model's optimization hits the maximum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1ccd29-10a8-4cee-99f2-0aa846a85a1e",
   "metadata": {},
   "source": [
    "- Cost function is the function of w.\n",
    "- Our goal is to find the minimum cost function and its parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60e094c-e2cd-47fe-a938-d9d0c6fbc918",
   "metadata": {},
   "source": [
    "#### Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f34394-2907-44a8-827b-6f0385edf8cb",
   "metadata": {},
   "source": [
    "In economics, the cost curve,expressing production costs in terms of amount produced. In mathematical optimization, the loss function, a function to be minimized. (source: https://en.wikipedia.org/wiki/Loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a1929a-941c-4785-a2bc-c3a617674470",
   "metadata": {},
   "source": [
    "A loss function or cost function is a function that maps an event or value of one or more variables onto a real number intuitively representing some 'cost' associated with the event. An optimization problem seeks to minimize a loss function. In this regard, an objective function is either a loss function or its opposite (reward function), in which case it is to be maximized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da3a518-9874-4aa8-bfbe-f2441a79534b",
   "metadata": {},
   "source": [
    "Selecting a loss function can depend on knowing the losses that will be experienced from being wrong under the problem's particular circumstances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4fb91d-d54d-4658-830d-a95a4f1448bc",
   "metadata": {},
   "source": [
    "- mean or average: the statistic for estimating location that minimizes the expected loss under the squared-error loss function.\n",
    "- median: the statistic for estimating location that minimizes the expected loss under the absolute-difference loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c3567b-39bf-4b04-80f3-88eb84c2354d",
   "metadata": {},
   "source": [
    "- risk neutral: the objective function is the expected value of a monetary quantity.\n",
    "- risk averse: the loss is measured as the negative of a utility function (reward), the objective function is the expected value of utility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19dd006-3e9a-42ef-92f1-9051cf87a5bd",
   "metadata": {},
   "source": [
    "#### Bayesian expected loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3e9de9-5090-444f-8b71-c95575d1c730",
   "metadata": {},
   "source": [
    "The expectation is calculated using the posterior distribution $\\pi$ of the parameter $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b659647-284a-450c-bc44-91c0d5b46b47",
   "metadata": {},
   "source": [
    "$$\n",
    "\\rho(\\pi^*, a) = \\int L(\\theta, a) d\\pi^*(\\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c36a41-1897-47f9-bef2-c777f635c510",
   "metadata": {},
   "source": [
    "The Bayesian approach is choosing the optimal action a under the actual observed data, whereas the Frequentist optimal decision rule is based on all possible observations, which is a much more difficult problem. Here, very commonly used loss functions are the squared loss, $L(a) = a^2$, and the absolute loss, $L(a) = |a|$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd927bf-3e52-40d2-a69b-84d0030c7e85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ff1947-8c73-4815-94f4-c16f2fe28eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
